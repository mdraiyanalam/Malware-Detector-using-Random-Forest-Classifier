{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72490750-049a-4a98-a0ef-2d910b8094e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    entropy  sections  imports  api_calls  label\n",
      "0  4.248357       3.0     38.0      152.0    0.0\n",
      "1  3.930868       7.0     45.0      271.0    0.0\n",
      "2  4.323844       7.0     22.0      317.0    0.0\n",
      "3  4.761515       3.0     41.0      259.0    0.0\n",
      "4  3.882923       3.0     16.0      297.0    0.0\n",
      "File saved successfully.\n"
     ]
    }
   ],
   "source": [
    "'''Making the Dataset'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 50  # 50 benign and 50 malware samples\n",
    "\n",
    "# Generate features for benign files\n",
    "benign_entropy = np.random.normal(loc=4.0, scale=0.5, size=num_samples)\n",
    "benign_sections = np.random.randint(3, 8, size=num_samples)\n",
    "benign_imports = np.random.randint(10, 50, size=num_samples)\n",
    "benign_api_calls = np.random.randint(100, 500, size=num_samples)\n",
    "\n",
    "# Generate features for malware files\n",
    "malware_entropy = np.random.normal(loc=7.0, scale=1.0, size=num_samples)\n",
    "malware_sections = np.random.randint(2, 6, size=num_samples)\n",
    "malware_imports = np.random.randint(50, 200, size=num_samples)\n",
    "malware_api_calls = np.random.randint(500, 1500, size=num_samples)\n",
    "\n",
    "# Create labels\n",
    "benign_labels = np.zeros(num_samples)\n",
    "malware_labels = np.ones(num_samples)\n",
    "\n",
    "# Combine features and labels\n",
    "benign_data = np.column_stack((benign_entropy, benign_sections, benign_imports, benign_api_calls, benign_labels))\n",
    "malware_data = np.column_stack((malware_entropy, malware_sections, malware_imports, malware_api_calls, malware_labels))\n",
    "\n",
    "# Combine benign and malware data\n",
    "data = np.vstack((benign_data, malware_data))\n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['entropy', 'sections', 'imports', 'api_calls', 'label']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Reset index to ensure it starts from 0 to 99\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "try:\n",
    "    # Use one of the methods above to correctly specify the path\n",
    "    df.to_csv(r'E:\\Semester 18th Summer 2024\\CSE499B Aqu\\malware_dataset.csv', index=False)  # Raw string method\n",
    "    print(\"File saved successfully.\")\n",
    "except PermissionError as e:\n",
    "    print(f\"Permission error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550200b1-6ee3-42cb-88c8-b3acdca771e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7022cd9a-79fd-42a1-b3fe-1061a9dd575e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    entropy  sections  imports  api_calls  label\n",
      "0  4.248357       3.0     38.0      152.0    0.0\n",
      "1  3.930868       7.0     45.0      271.0    0.0\n",
      "2  4.323844       7.0     22.0      317.0    0.0\n",
      "3  4.761515       3.0     41.0      259.0    0.0\n",
      "4  3.882923       3.0     16.0      297.0    0.0\n",
      "Selected features: ['entropy', 'imports', 'api_calls']\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\mdrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "'''Load the Data'''\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(r'E:\\Semester 18th Summer 2024\\CSE499B Aqu\\malware_dataset.csv')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(data.head())\n",
    "\n",
    "'''Preprocess the Data'''\n",
    "import numpy as np\n",
    "\n",
    "# Check for and handle missing values\n",
    "if data.isnull().sum().any():\n",
    "    data = data.dropna()  # Or use another method to handle missing values\n",
    "\n",
    "# Check for infinite values\n",
    "if np.isinf(data).any().any():\n",
    "    data = data.replace([np.inf, -np.inf], np.nan).dropna()  # Or use another method to handle infinite values\n",
    "\n",
    "\n",
    "'''Feature Selection'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into features and target\n",
    "X = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a RandomForest model for feature selection\n",
    "feature_selector = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "feature_selector.fit(X_train, y_train)\n",
    "\n",
    "# Select important features\n",
    "select_model = SelectFromModel(feature_selector, threshold='mean', prefit=True)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train_selected = select_model.transform(X_train)\n",
    "X_test_selected = select_model.transform(X_test)\n",
    "\n",
    "# Convert transformed data back to DataFrame to retain feature names\n",
    "selected_features = X.columns[select_model.get_support()]\n",
    "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features)\n",
    "\n",
    "print(\"Selected features:\", selected_features.tolist())\n",
    "\n",
    "'''Hyperparameter Tuning and Model Evaluation'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Perform hyperparameter tuning and model selection using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1',\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set with the best model\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc42aba-a836-4242-9a46-2700c6c8a34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644f7266-6ecd-4dae-b1b1-9a0b58a880ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 248-249: truncated \\UXXXXXXXX escape (3166308076.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 248-249: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "- Point to think?\n",
    "- 1) where did you find the dataset?\n",
    "- 2) Why did you choose random forest\n",
    "- 3) explain your code\n",
    "- 4) Did you train you code?\n",
    "- 5) Did you test your code in real time?\n",
    "- 6) Is the preprecessing done correctly?\n",
    "- 7) Cannot fix the below code?\n",
    "- C:\\Users\\mdrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
    "  warnings.warn(\n",
    "- C:\\Users\\mdrai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
    "  warnings.warn(\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5975dd-e9ee-410f-91e7-bc22aa3f07c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
